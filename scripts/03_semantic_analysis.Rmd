---
title: "03_analysis"
author: "Helen Wang"
date: "2025-11-16"
output: html_document
---

#### Library

```{r}
#load packages
pacman::p_load(
  dplyr,
  tidyr,
  purrr,
  quanteda,
  text2vec,
  tibble,
  vegan,
  ggplot2,
  wordvector,
  parallel,
  Rtsne,
  ggrepel
)

source("functions.R")
```

#### Reading in Files

```{r}
#read in files
df <- read.csv("../data/scraping_results.csv", na.strings = "") %>%
  mutate(post2018 = ifelse(post2018 == "True", TRUE, FALSE))
```

#### Preprocessing

```{r}
#check distributions
table(df$post2018)

#convert to corpus
news_corpus <- corpus(df, text_field = "full_text")

#n-grams I want to retain
n_grams_keep <- c(
  "new york city", "new york", "bill de blasio", "de blasio", 
  "high school", "high schools", "specialized high schools", 
  "specialized high school", "specialized schools", "zohran mandani", 
  "eric adams", "michael bloomberg"
)
```
#### Alignment Method with Boostrap Resampling to Stablilize Results

Using GLOVE since it also handles small corpora better

###### Bootstrap Resampling

```{r, include = FALSE}
#bootstrap iterations
total_iter <- 100

#storage
word_vectors <- vector(mode = "list", length = total_iter)
names(word_vectors) <- 1:100

master_word_list <- vector(mode = "list", length = total_iter)
names(master_word_list) <- 1:100


#boostrap resample of GLOVE

for (iter in 1:total_iter) {
  
  #get dataset
  pre <- sample_news(df, post = F)
  post <- sample_news(df, post = T)
  
  #preprocess for each time period
  pre2018_news <- process_corpus(pre, n_grams_keep)
  post2018_news <- process_corpus(post, n_grams_keep)
  
  #identify features that appear in both periods
  period_words <- shared_words(pre2018_news, post2018_news)
  
  #get glove for both periods
  pre2018_mat_untidy <- glove_matrix(tidy = F, pre2018_news, period_words) 
  post2018_mat_untidy <- glove_matrix(tidy = F, post2018_news, period_words)
  
  #aligning across periods
  aligned <- procrustes(pre2018_mat_untidy, post2018_mat_untidy)
  
  #cleaning up data
  pre_2018_aligned <- aligned$X %>% 
    as.data.frame() %>%
    rename_with(~ gsub("Dim", "V", .x)) %>%
    mutate(
      vocab = rownames(.)
    ) %>%
    select(vocab, everything()) %>%
    mutate(period = "Pre 2018")

  post_2018_aligned <- aligned$Yrot %>% 
    as.data.frame() %>%
    mutate(
      vocab = rownames(.)
    ) %>%
    select(vocab, everything())  %>%
    mutate(period = "Post 2018")
  
  #append as list
  word_vectors[[iter]] <- list(
    pre = pre_2018_aligned,
    post = post_2018_aligned
  )
  
  master_word_list[[iter]] <- period_words
}
```

###### Cosine Similarity for each Iteration

```{r}
#empty dataframe
similarity_list <- vector("list", length(word_vectors))
names(similarity_list) <- 1:length(word_vectors)

#loop to compute
for (i in 1:length(word_vectors)) {
  #get word list
  word_list <- word_vectors[[i]][["pre"]]$vocab
  
  iter_results <- lapply(
    word_list, function(word) {
      #compute cosine
      word_sim <- temporal_similarity(
        word,  word_vectors[[i]][["pre"]], word_vectors[[i]][["post"]], method = "aligned"
      )
      #tidy results
      data.frame(
        word = word,
        temporal_cosine_similarity = word_sim,
        iteration = i,
        stringsAsFactors = F
      )
    }
  )
  
  similarity_list[[i]] <- iter_results
  
}

#convert list to df
similarity_df <- bind_rows(similarity_list) 
```


###### Averaging Cosine Similarity Across Vectors

```{r}
#averages cosine similarity across vectors
similarity_tidy <- similarity_df %>%
  pivot_wider(
    names_from = "word",
    values_from = "temporal_cosine_similarity"
  ) %>%
  select(-iteration) %>%
  summarise(
    across(
      everything(),
      list(
         mean = ~ mean(., na.rm = T),
         se   = ~ sd(., na.rm = T) / sqrt(length(.))
       ),
      .names = "{.col}__{.fn}"
    )
  ) %>%
  pivot_longer(
    everything(),
    names_to = c("vocab", "variable"),
    names_sep = "__"
  ) %>%
  pivot_wider(
    names_from = variable,
    values_from = value
  ) %>%
  mutate(
    ci_lower = mean - 1.96*se,
    ci_high = mean + 1.96*se
  )


```


###### Plotting Cosine Similarity of Words of Interest

```{r}
#list of words
top_words <- news_corpus %>% 
  process_corpus(n_grams_keep) %>% 
  tokens_remove(stopwords("en")) %>%
  dfm() %>% 
  topfeatures(n = 1000)

#pick words based on top words
words_of_interest <- c(
  "test", "shsat", "high_school",
  "specialized_high_schools", "high_schools",
  "specialized_high_school", "black", "exam",
  "asian", "hispanic", "latino", "racial",
  "segregation", "race", "equity", "white",
  "asian-american", "diversify", "integration",
  "merit", "segregated", "minority", "meritocracy",
  "low-income", "african", "minorities", "socioeconomic"
)

#make sure words of interest or in period words
words_of_interest <- intersect(words_of_interest, unique(similarity_tidy$vocab))

#plotting cosine similarity
similarity_tidy %>%
  filter(vocab %in% words_of_interest) %>%
  mutate(
    above_zero = mean > 0 
  ) %>%
  ggplot(aes(x = vocab, y = mean, fill = above_zero)) +
  geom_col() + 
  geom_point(color = "grey50") +
  geom_errorbar(
    aes(
      ymin = ci_lower, ymax = ci_high
    ),
    width = 0.2, color = "grey70"
  ) +
  coord_flip() +
  theme_minimal() +
  labs(
    x = "Vocabulary",
    y = "Average Cosine Similarity across Periods",
    title = "How Similar are Words Pre- and Post- 2018?",
    caption = "Aligned Time Series Model"
  ) +
  theme(
    legend.position = "none"
  ) 
```

###### Aligning Word Embeddings for TSNE

```{r}
#only keep words of interest that are in all iterations
words_of_interest2 <- intersect(Reduce(intersect, master_word_list), words_of_interest)

#select pre and post embeddings for reference
ref_pre <- word_vectors[[1]]["pre"] %>% 
  as.data.frame() %>% 
  rename_with(~ gsub("pre.", "", .x)) %>% 
  filter(vocab %in% words_of_interest2) %>%
  select(-vocab, -period) %>% 
  as.matrix()
ref_post <- word_vectors[[1]]["post"] %>% 
  as.data.frame() %>%
  rename_with(~ gsub("post.", "", .x)) %>% 
  filter(vocab %in% words_of_interest2) %>%
  select(-vocab, -period) %>% 
  as.matrix()

#list to store alignments
pre_aligned <- vector(mode = "list", length = length(word_vectors) - 1)
post_aligned <- vector(mode = "list", length = length(word_vectors) - 1)

#align all embeddings to ref

for (vec in 2:length(word_vectors)) {
  
  #convert to matrix 
  pre_mat <- word_vectors[[vec]]["pre"] %>% 
    as.data.frame() %>% 
    rename_with(~ gsub("pre.", "", .x)) %>% 
    filter(vocab %in% words_of_interest2) %>%
    select(-vocab, -period) %>% 
    as.matrix()
  
  post_mat <- word_vectors[[vec]]["post"] %>% 
    as.data.frame() %>% 
    rename_with(~ gsub("post.", "", .x)) %>% 
    filter(vocab %in% words_of_interest2) %>%
    select(-vocab, -period) %>% 
    as.matrix()
  
  #align and add to list
  pre_aligned[[vec - 1]] <- procrustes(ref_pre, pre_mat)
  post_aligned[[vec - 1]] <- procrustes(ref_post, post_mat)
}

#tidy up results

pre_aligned_df <- data.frame(matrix(nrow = 0, ncol = 4))
post_aligned_df <- data.frame(matrix(nrow = 0, ncol = 4))

# Pre - 2018

for (i in 1:length(pre_aligned)) {
  #append ref as well
  if (i == 1 ) {
    ref_append <- pre_aligned[[i]]$X %>% 
      as.data.frame() %>%
      rename_with(~ gsub("Dim", "V", .x)) %>%
      mutate(
        vocab = rownames(.)
      ) %>%
      select(vocab, everything()) %>%
    pivot_longer(
      !vocab,
      names_to = "feature",
      values_to = "value"
    ) %>%
    mutate(
      category = "Reference"
    )
    
    y_append <- pre_aligned[[i]]$Yrot %>% 
      as.data.frame() %>%
      rename_with(~ gsub("Dim", "V", .x)) %>%
      mutate(
        vocab = rownames(.)
      ) %>%
      select(vocab, everything()) %>%
    pivot_longer(
      !vocab,
      names_to = "feature",
      values_to = "value"
    ) %>%
    mutate(
      category = "Y"
    )
    
    #add to dataframe
    pre_aligned_df <- rbind(pre_aligned_df, ref_append)
    pre_aligned_df <- rbind(pre_aligned_df, y_append)
  } else {
    
    y_append <- pre_aligned[[i]]$Yrot %>% 
      as.data.frame() %>%
      rename_with(~ gsub("Dim", "V", .x)) %>%
      mutate(
        vocab = rownames(.)
      ) %>%
      select(vocab, everything()) %>%
    pivot_longer(
      !vocab,
      names_to = "feature",
      values_to = "value"
    ) %>%
    mutate(
      category = "Y"
    )
    
    #add to dataframe
    pre_aligned_df <- rbind(pre_aligned_df, y_append)
  }
}

# Post - 2018

for (i in 1:length(post_aligned)) {
  #append ref as well
  if (i == 1 ) {
    ref_append <- post_aligned[[i]]$X %>% 
      as.data.frame() %>%
      rename_with(~ gsub("Dim", "V", .x)) %>%
      mutate(
        vocab = rownames(.)
      ) %>%
      select(vocab, everything()) %>%
    pivot_longer(
      !vocab,
      names_to = "feature",
      values_to = "value"
    ) %>%
    mutate(
      category = "Reference"
    )
    
    y_append <- post_aligned[[i]]$Yrot %>% 
      as.data.frame() %>%
      rename_with(~ gsub("Dim", "V", .x)) %>%
      mutate(
        vocab = rownames(.)
      ) %>%
      select(vocab, everything()) %>%
    pivot_longer(
      !vocab,
      names_to = "feature",
      values_to = "value"
    ) %>%
    mutate(
      category = "Y"
    )
    
    #add to dataframe
    post_aligned_df <- rbind(post_aligned_df, ref_append)
    post_aligned_df <- rbind(post_aligned_df, y_append)
  } else {
    
    y_append <- post_aligned[[i]]$Yrot %>% 
      as.data.frame() %>%
      rename_with(~ gsub("Dim", "V", .x)) %>%
      mutate(
        vocab = rownames(.)
      ) %>%
      select(vocab, everything()) %>%
    pivot_longer(
      !vocab,
      names_to = "feature",
      values_to = "value"
    ) %>%
    mutate(
      category = "Y"
    )
    
    #add to dataframe
    post_aligned_df <- rbind(post_aligned_df, y_append)
  }
}

```

##### Averaging Aligned Word Embeddings for TSNE

```{r}
avg_pre_aligned <- pre_aligned_df %>%
  select(-category) %>%
  pivot_wider(
    id_cols = vocab,
    names_from = feature,
    values_from = value,
    values_fn = list
  ) %>%
  mutate(across(!vocab, ~ map_dbl(.x, mean)))  %>%
  rename(rowname = vocab) %>%
  column_to_rownames()


avg_post_aligned <- post_aligned_df %>%
  select(-category) %>%
  pivot_wider(
    id_cols = vocab,
    names_from = feature,
    values_from = value,
    values_fn = list
  ) %>%
  mutate(across(!vocab, ~ map_dbl(.x, mean))) %>%
  rename(rowname = vocab) %>%
  column_to_rownames()

#converting to 2D

tsne_pre2018 <- avg_pre_aligned %>% as.matrix() %>% Rtsne(dims = 2, perplexity = 2)
tsne_post2018 <- avg_post_aligned %>% as.matrix() %>% Rtsne(dims = 2, perplexity = 2)
```

##### Plotting TSNE

```{r}
#merging them
tsne_df <- rbind(
  data.frame(
    x = tsne_pre2018$Y[,1], y =  tsne_pre2018$Y[,2], word = row.names(avg_pre_aligned), period = "Pre"
  ), 
  data.frame(
    x = tsne_post2018$Y[,1], y =  tsne_post2018$Y[,2], word = row.names(avg_post_aligned), period = "Post"
  )
)

#converting to wide form
tsne_wide <- tsne_df %>% 
  pivot_wider(names_from = "period", values_from = c(x, y))

#color palette for legend
palette <- c("Pre 2018" = "cyan", "Post 2018" = "coral")

#plot in vector space
tsne_wide %>%
  ggplot() +
  geom_label(aes(x = x_Pre, y = y_Pre, label = word, color = "Pre 2018")) +
  geom_label(aes(x = x_Post, y = y_Post, label = word, color = "Post 2018")) +
  geom_segment(aes(
    x = x_Pre, y = y_Pre, xend = x_Post, yend = y_Post,
  ),
  linetype = "dashed",
  color = "grey50",
  arrow = arrow(length = unit(0.2, "cm"), type = "closed")) +
  theme_minimal() +
  labs(
    x = "X",
    y = "Y",
    title = "Mapping Diachronic Semantic Shift",
    color = "Time Period"
  ) +
  scale_color_manual(values = palette)

#alternative plot
tsne_df %>%
  mutate(
    period = factor(period, levels = c("Pre", "Post"))
  ) %>%
  ggplot() +
  geom_label(aes(x = x, y = y, label = word, color = period)) +
  theme_minimal() +
  scale_x_continuous(limits = c(-2500, 2500)) +
  labs(
    x = "X",
    y = "Y",
    title = "Mapping Diachronic Semantic Shift",
    color = "Time Period"
  ) +
  facet_grid(~ period)

```
##### Computing Change in Cosine Similarity between Word Pairs

```{r}
#create word combinations
word_combos <- combn(words_of_interest2, m = 2, simplify = F)

#combination cosine similarity
comb_simil_df <- data.frame(matrix(nrow = 0, ncol = 4))

#loop to compute word combo cosine similarity
for (vec in word_vectors) {
  #pull matrix
  pre <- vec[["pre"]] %>% as.data.frame()
  post <- vec[["post"]] %>% as.data.frame()
  
  for (combo in word_combos) {
    #grab pre vocab
    
    pre_word1 <- as.numeric(pre[pre$vocab == combo[1],] %>% select(-period, -vocab))
    pre_word2 <- as.numeric(pre[pre$vocab == combo[2],] %>% select(-period, -vocab))
    
    #grab post vocab
  
    post_word1 <- as.numeric(post[post$vocab == combo[1],] %>% select(-period, -vocab))
    post_word2 <- as.numeric(post[post$vocab == combo[2],] %>% select(-period, -vocab))
    
    #combine cosine similarity
    
    pre_sim <- sim2(
      matrix(pre_word1, nrow = 1), 
      matrix(pre_word2, nrow = 1),
      method = "cosine"
    )
    
    post_sim <- sim2(
      matrix(post_word1, nrow = 1), 
      matrix(post_word2, nrow = 1),
      method = "cosine"
    )
    
    #save to dataframe
    comb_simil_df <- rbind(
      comb_simil_df, 
      c(combo[1], combo[2], pre_sim, post_sim)
    )
  }
}

#rename dataframe
colnames(comb_simil_df) <- c("word1", "word2", "pre", "post")

#tidying up dataframe
comb_simil_df_tidy <- comb_simil_df %>%
  mutate(
    word_combo = paste0(word1, " - ", word2),
    pre = as.numeric(pre),
    post = as.numeric(post)
  ) %>%
  select(-word1, -word2) %>%
  group_by(word_combo) %>% 
  summarise(
    pre = mean(pre, na.rm = T),
    post = mean(post, na.rm = T),
    .groups = "drop"
  ) 
  

#plot
period_palette <- c("coral", "cyan") %>% setNames(c("Pre-2018", "Post-2018"))

comb_simil_df_tidy %>%
  ggplot() +
  geom_point(aes(y = word_combo, x = pre, col = "Pre 2018")) +
  geom_point(aes(y = word_combo, x = post, col = "Post 2018")) +
  geom_segment(aes(y = word_combo, yend = word_combo,
                   x = pre, xend = post),
               color = "grey30",
               arrow = arrow(length = unit(1, "mm"))) +
  theme_minimal() +
  labs(
    x = "Cosine Similarity",
    y = "",
    title = "Change in Cosine Similarity across Periods",
    colour = "Period"
  ) +
  scale_color_manual(values = palette)

```

#### Chronologically trained method

###### Initalize on Full Corpus

```{r}
#process full text
processed_news <- process_corpus(news_corpus, n_grams_keep)

#initalize mod
full_wv <- textmodel_word2vec(processed_news, 
                   dim = 50,
                   min_count = 0, 
                   window = 6,
                   iters = 15
                   )
```

###### Bootstrap Resampling and Training

```{r}
#bootstrap iterations
total_iter <- 100

#storage
chrono_mods <- vector(mode = "list", length = total_iter)
names(chrono_mods) <- 1:100

chrono_word_list <- vector(mode = "list", length = total_iter)
names(chrono_word_list) <- 1:100

#boostrap models of the first era

for (iter in 1:total_iter) {
  
  #get dataset
  pre <- sample_news(df, post = F)
  post <- sample_news(df, post = T)
  
  #preprocess for each time period
  pre2018_news <- process_corpus(pre, n_grams_keep)
  post2018_news <- process_corpus(post, n_grams_keep)
  
  #add first slice
  wv_pre <- textmodel_word2vec(pre2018_news, 
                   model = full_wv,
                   dim = 50,
                   min_count = 0, 
                   window = 6,
                   iters = 15
                   )
  #add second slice
  wv_post <- textmodel_word2vec(post2018_news,
                    model = wv_pre,
                    dim = 50,
                    min_count = 0, 
                    window = 6,
                    iters = 15
                    )
  
  #identify features that appear in both periods
  period_words <- intersect(wv_pre$values %>% rownames(), wv_post$values %>% rownames())
  
  #append
  chrono_mods[[iter]] <- list(
    pre = wv_pre,
    post = wv_post
  )
  
  chrono_word_list[[iter]] <- period_words
}
```

##### Cosine Similarity Calculations

```{r}
#empty dataframe
chrono_similarity <- vector("list", length(chrono_mods))
names(chrono_similarity) <- 1:length(chrono_mods)

#loop to compute
for (i in 1:length(chrono_mods)) {
  #grab models
  pre_mod <- chrono_mods[[i]][["pre"]]
  post_mod <- chrono_mods[[i]][["post"]]
  
  #get word_list
  word_list <- chrono_word_list[[i]]
  
  #iterate through each word for cosine similarity
  iter_results <- lapply(
    word_list, function(word) {
      #compute cosine
      word_sim <- temporal_similarity(
        word, pre_mod, post_mod, method = "chrono"
      )
      #tidy results
      data.frame(
        word = word,
        temporal_cosine_similarity = word_sim,
        iteration = i,
        stringsAsFactors = F
      )
    }
  )
  
  chrono_similarity[[i]] <- iter_results
  
}

#convert list to df
chrono_similarity_df <- bind_rows(chrono_similarity) 


#averages cosine similarity across vectors
chrono_similarity_tidy <- chrono_similarity_df %>%
  filter(word %in% words_of_interest) %>%
  pivot_wider(
    names_from = "word",
    values_from = "temporal_cosine_similarity"
  ) %>%
  select(-iteration) %>%
  summarise(
    across(
      everything(),
      list(
         mean = ~ mean(., na.rm = T),
         se   = ~ sd(., na.rm = T) / sqrt(length(.))
       ),
      .names = "{.col}__{.fn}"
    )
  ) %>%
  pivot_longer(
    everything(),
    names_to = c("vocab", "variable"),
    names_sep = "__"
  ) %>%
  pivot_wider(
    names_from = variable,
    values_from = value
  ) %>%
  mutate(
    ci_lower = mean - 1.96*se,
    ci_high = mean + 1.96*se
  )
```

##### Plotting Cosine Similarity

```{r}
chrono_similarity_tidy %>%
  mutate(
    above_zero = mean > 0 
  ) %>%
  ggplot(aes(x = vocab, y = mean, fill = above_zero)) +
  geom_col() + 
  geom_point(color = "grey50") +
  geom_errorbar(
    aes(
      ymin = ci_lower, ymax = ci_high
    ),
    width = 0.2, color = "grey70"
  ) +
  coord_flip() +
  theme_minimal() +
  labs(
    x = "Vocabulary",
    y = "Average Cosine Similarity across Periods",
    title = "How Similar are Words Pre- and Post- 2018?",
    caption = "Chronologically Trained Model"
  ) +
  theme(
    legend.position = "none"
  ) +
  scale_fill_manual(values = c("#52d8da", "#fbaca7"))


combined_simil_tidy <- similarity_tidy %>%
  filter(vocab %in% words_of_interest) %>%
  mutate(
    above_zero = mean > 0 
  ) %>%
  mutate(
    model = "Aligned Time Series Model"
  ) %>%
  rbind(
    chrono_similarity_tidy %>%
      mutate(
        above_zero = mean > 0,
        model = "Chronologically Trained Model"
      ) 
  ) 

combined_simil_tidy %>%
  ggplot(aes(x = vocab, y = mean, fill = above_zero)) +
  geom_col() + 
  geom_point(color = "grey50") +
  geom_errorbar(
    aes(
      ymin = ci_lower, ymax = ci_high
    ),
    width = 0.2, color = "grey70"
  ) +
  coord_flip() +
  facet_grid(~model) +
  theme_minimal() +
  labs(
    x = "Vocabulary",
    y = "Average Cosine Similarity across Periods",
    title = "How Similar are Words Pre- and Post- 2018?",
    subtitle = "Comparing Different Diachronic Models"
  ) +
  theme(
    legend.position = "none"
  ) +
  scale_fill_manual(values = c("#52d8da", "#fbaca7")) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, face = "italic")
  )


combined_simil_tidy %>%
  group_by(model) %>%
  summarise(mean_simil = mean(mean, na.rm = T),
            se_simil = mean(se, na.rm = T))

```

##### Combining Embeddings for TSNE

```{r}
comb_chrono_df <- data.frame(matrix(nrow = 0, ncol = 4))

#tidying embeddings

for (i in 1:length(chrono_mods)) {
  for (ver in 1:2) {
    append <- chrono_mods[[i]][[ver]]$values %>%
      as.data.frame() %>%
      mutate(vocab = rownames(.)) %>%
      select(vocab, everything()) %>%
      pivot_longer(!vocab, names_to = "feature", values_to = "value") %>%
      mutate(category = i)
    
    if (ver == 1) {
      append <- append %>%
        mutate(period = "Pre")
    } else if (ver == 2) {
      append <- append %>%
        mutate(period = "Post")
    }
  
    #add to dataframe
    comb_chrono_df <- rbind(comb_chrono_df, append)
  }
}


#averaging embeddings

avg_comb_chrono_df <- comb_chrono_df %>%
  group_by(vocab, feature, period) %>%
  summarise(
    value = mean(value, na.rm = T),
    .groups = "drop"
  ) %>%
  pivot_wider(
    id_cols = c(vocab, period),
    names_from = feature,
    values_from = value
  )
```

##### Visualizing Word Embeddings

```{r}
#tidying them up
chr_pre <- avg_comb_chrono_df %>%
  filter(period == "Pre") %>%
  select(-period) %>%
  rename(rowname = vocab) %>%
  column_to_rownames() 

chr_post <- avg_comb_chrono_df %>%
  filter(period == "Post") %>%
  select(-period) %>%
  rename(rowname = vocab) %>%
  column_to_rownames() 

#compute words of interest
words_of_interest3 <- intersect(intersect(rownames(chr_pre), rownames(chr_post)), words_of_interest)

#convert to 2D
tsne_chr_pre <- chr_pre %>%
  filter(rownames(.) %in% words_of_interest3) %>%
  Rtsne(dims = 2, perplexity = 7)

tsne_chr_post <- chr_post %>%
  filter(rownames(.) %in% words_of_interest3) %>%
  Rtsne(dims = 2, perplexity = 7)

#merging them
tsne_chr_df <- rbind(
  data.frame(
    x = tsne_chr_pre$Y[,1], y =  tsne_chr_pre$Y[,2], word = words_of_interest3, period = "Pre"
  ), 
  data.frame(
    x = tsne_chr_post$Y[,1], y =  tsne_chr_post$Y[,2], word = words_of_interest3, period = "Post"
  )
)

#converting to wide form
tsne_chr_wide <- tsne_chr_df %>% 
  pivot_wider(names_from = "period", values_from = c(x, y))


#plot into vector space
tsne_chr_wide %>%
  ggplot() +
  geom_label(aes(x = x_Pre, y = y_Pre, label = word, color = "Pre 2018"), alpha = 0.7) +
  geom_label(aes(x = x_Post, y = y_Post, label = word, color = "Post 2018"), alpha = 0.7) +
  geom_segment(aes(
    x = x_Pre, y = y_Pre, xend = x_Post, yend = y_Post,
  ),
  linetype = "dashed",
  color = "grey50",
  arrow = arrow(length = unit(0.1, "cm"), type = "closed")) +
  theme_minimal() +
  labs(
    x = "X",
    y = "Y",
    title = "Mapping Diachronic Semantic Shift",
    color = "Time Period",
    caption = "Chronologically Trained Model"
  ) +
  scale_color_manual(values = palette) +
  scale_x_continuous(limits = c(-200, 200))  +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, face = "italic")
  )


#alternative plot
tsne_chr_df %>%
  ggplot() +
  geom_label(aes(x = x, y = y, label = word, color = period)) +
  theme_minimal() +
  scale_x_continuous(limits = c(-2500, 2500)) +
  labs(
    x = "X",
    y = "Y",
    title = "Mapping Diachronic Semantic Shift",
    color = "Time Period"
  ) +
  facet_grid(~ period) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, face = "italic")
  )
```
##### Computing Change in Cosine Similarity between Word Pairs

```{r}
#create word combinations
word_combos2 <- combn(words_of_interest3, m = 2, simplify = F)

#combination cosine similarity
comb_simil_df2 <- data.frame(matrix(nrow = 0, ncol = 4))

#loop to compute word combo cosine similarity
for (vec in chrono_mods) {
  #pull matrix
  pre <- vec[["pre"]]$values %>% as.data.frame() %>% mutate(vocab = rownames(.))
  post <- vec[["post"]]$values %>% as.data.frame() %>% mutate(vocab = rownames(.))
  
  for (combo in word_combos2) {
    #grab pre vocab
    
    pre_word1 <- as.numeric(pre[pre$vocab == combo[1],] %>% select(-vocab))
    pre_word2 <- as.numeric(pre[pre$vocab == combo[2],] %>% select(-vocab))
    
    #grab post vocab
  
    post_word1 <- as.numeric(post[post$vocab == combo[1],] %>% select(-vocab))
    post_word2 <- as.numeric(post[post$vocab == combo[2],] %>% select(-vocab))
    
    #combine cosine similarity
    
    pre_sim <- sim2(
      matrix(pre_word1, nrow = 1), 
      matrix(pre_word2, nrow = 1),
      method = "cosine"
    )
    
    post_sim <- sim2(
      matrix(post_word1, nrow = 1), 
      matrix(post_word2, nrow = 1),
      method = "cosine"
    )
    
    #save to dataframe
    comb_simil_df2 <- rbind(
      comb_simil_df2, 
      c(combo[1], combo[2], pre_sim, post_sim)
    )
  }
}

#rename dataframe
colnames(comb_simil_df2) <- c("word1", "word2", "pre", "post")

#tidying up dataframe
comb_simil_df_tidy_2 <- comb_simil_df2 %>%
  mutate(
    word_combo = paste0(word1, " - ", word2),
    pre = as.numeric(pre),
    post = as.numeric(post)
  ) %>%
  select(-word1, -word2) %>%
  group_by(word_combo) %>% 
  summarise(
    pre = mean(pre, na.rm = T),
    post = mean(post, na.rm = T),
    .groups = "drop"
  ) 
  

#plot
period_palette <- c("coral", "cyan") %>% setNames(c("Pre-2018", "Post-2018"))

comb_simil_df_tidy_2 %>%
  filter(word_combo %in% comb_simil_df_tidy$word_combo) %>%
  ggplot() +
  geom_point(aes(y = word_combo, x = pre, col = "Pre 2018")) +
  geom_point(aes(y = word_combo, x = post, col = "Post 2018")) +
  geom_segment(aes(y = word_combo, yend = word_combo,
                   x = pre, xend = post),
               color = "grey30",
               arrow = arrow(length = unit(1, "mm"))) +
  theme_minimal() +
  labs(
    x = "Cosine Similarity",
    y = "",
    title = "Change in Cosine Similarity across Periods",
    colour = "Period"
  ) +
  scale_color_manual(values = palette) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, face = "italic")
    )

#change in cosine similarity for specific words
for (word in c("shsat", "exam", "equity", "race","diversify", "merit")) {
  print(cos_similarity_plot(comb_simil_df_tidy_2, word))
}

#highest cosine similarity changes
comb_simil_df_tidy_2 %>%
  mutate(
    change = post - pre,
    change = abs(change)
  ) %>%
  arrange(desc(change)) %>%
  head(25) %>%
  ggplot() +
  geom_point(aes(y = word_combo, x = pre, col = "Pre 2018")) +
  geom_point(aes(y = word_combo, x = post, col = "Post 2018")) +
  geom_segment(aes(y = word_combo, yend = word_combo,
                   x = pre, xend = post),
               color = "grey30",
               arrow = arrow(length = unit(1, "mm"))) +
  theme_minimal() +
  labs(
    x = "Cosine Similarity",
    y = "",
    title = "Change in Cosine Similarity across Periods",
    colour = "Period"
  ) +
  scale_color_manual(values = palette) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, face = "italic")
    )

#lowest cosine similarity changes
comb_simil_df_tidy_2 %>%
  mutate(
    change = post - pre,
    change = abs(change)
  ) %>%
  arrange(desc(change)) %>%
  tail(25) %>%
  ggplot() +
  geom_point(aes(y = word_combo, x = pre, col = "Pre 2018")) +
  geom_point(aes(y = word_combo, x = post, col = "Post 2018")) +
  geom_segment(aes(y = word_combo, yend = word_combo,
                   x = pre, xend = post),
               color = "grey30",
               arrow = arrow(length = unit(1, "mm"))) +
  theme_minimal() +
  labs(
    x = "Cosine Similarity",
    y = "",
    title = "Change in Cosine Similarity across Periods",
    colour = "Period"
  ) +
  scale_color_manual(values = palette) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, face = "italic")
    )
```

